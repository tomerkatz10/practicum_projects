{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ee4b5be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from dateutil import parser\n",
    "import time\n",
    "import math\n",
    "import threading\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c57b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "Feed = feedparser.parse('https://www.investing.com/rss/news_25.rss')\n",
    "print(Feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1462f06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pointer = Feed.entries[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684024ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (pointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d5244aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ced211",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0e93eb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _default_rss_attributes_method(entry):\n",
    "    return (entry[\"title\"], _default_rss_datetime_converter(entry), entry[\"title_detail\"][\"base\"])\n",
    "\n",
    "def _default_rss_datetime_converter(entry):\n",
    "    try:\n",
    "        dt = parser.parse(entry[\"published\"])\n",
    "        dts = dt.strftime(\"%Y-%m-%dT%H:%M:%S\") + \" UTC\"\n",
    "        return datetime(dts)\n",
    "    except:\n",
    "        return now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "37111f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_single_rss_entry(rss_feed_url):\n",
    "    \"\"\"\n",
    "    This method returns a single entry from the given RSS feed. This is mostly used\n",
    "    for debugging and simple testing.\n",
    "    Parameters:\n",
    "        rss_feed_url (str): The RSS feed URL as a string.\n",
    "    Returns:\n",
    "        dict: A single entry from the RSS feed.\n",
    "    \"\"\"\n",
    "    return feedparser.parse(rss_feed_url).entries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "26d4dd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_rss_continual(rss_feed_urls, rss_attributes_method=None, rss_datetime_converter=None,\n",
    "        sleep_time=5, column_names=None, column_types=None, thread_count=None):\n",
    "    \"\"\"\n",
    "    This method continually reads from an RSS feed and stores its data in a Deephaven table.\n",
    "    Data is only written to the Deephaven table if it's new data. This is determined by the timestamp of the entries.\n",
    "    This method works best with RSS feeds that are always ordered by date-time, and update frequently. Some\n",
    "    examples of this are Reddit and Hackernews RSS feeds.\n",
    "    This method is highly customizeable. rss_attributes_method, column_names, and column_types define the resulting\n",
    "    Deephaven table, and rss_datetime_converter allows you to define how the datetime of the entry is computed. sleep_time\n",
    "    can be customized for performance (a larger value is useful for feeds that don't update often, while a smaller value\n",
    "    is better for feeds that update quickly).\n",
    "    thread_count can be used to run the RSS reader across multiple threads.\n",
    "    Parameters:\n",
    "        rss_feed_urls (list<str>): A list of RSS feed URLs to view.\n",
    "        rss_attributes_method (method): A method that converts an RSS entry to a tuple of values to write.\n",
    "        rss_datetime_converter (method): A method that takes an RSS feed entry and converts it to a Deephaven datetime object.\n",
    "            This should be customized based on the RSS feed.\n",
    "        sleep_time (int): An integer representing the number of seconds to wait between\n",
    "            RSS pulls if data hasn't changed.\n",
    "        column_names (list<str>): A list of column names for the resulting table.\n",
    "        column_types (list<dht.type>): A list of column types for the resulting table.\n",
    "        thread_count (int): How many threads to run the RSS reader in. If not set, 1 thread will be used.\n",
    "    Returns:\n",
    "        Table: The Deephaven table that will contain the results from the RSS feed.\n",
    "    \"\"\"\n",
    "    def thread_function(rss_feed_urls, rss_attributes_method, rss_datetime_converter, sleep_time, table_writer):\n",
    "        last_updated_list = [None for i in range(len(rss_feed_urls))]\n",
    "\n",
    "        while True:\n",
    "            rss_feed_url_index = 0\n",
    "            updated = False\n",
    "            while rss_feed_url_index < len(rss_feed_urls):\n",
    "                rss_feed_url = rss_feed_urls[rss_feed_url_index]\n",
    "                last_updated = last_updated_list[rss_feed_url_index]\n",
    "                feed = feedparser.parse(rss_feed_url)\n",
    "\n",
    "                i = 0\n",
    "                while i < len(feed.entries):\n",
    "                    try:\n",
    "                        entry = feed.entries[i]\n",
    "                        datetime_attribute = rss_datetime_converter(entry)\n",
    "\n",
    "                        #If no datetime, break\n",
    "                        if datetime_attribute is None:\n",
    "                            break\n",
    "\n",
    "                        #If data has previously been read, and the current item has a timestamp less than or equal\n",
    "                        #to the last item written to the table in the previous pull, then stop writing data.\n",
    "                        #RSS feeds can unpublish data, so a strict equality comparison can't work.\n",
    "                        #This may result in lost data if the RSS feed can publish multiple items with the same timestamp.\n",
    "                        if not (last_updated is None) and datetime_attribute <= last_updated:\n",
    "                            break\n",
    "\n",
    "                        write_row = rss_attributes_method(entry)\n",
    "                        table_writer.write_row(write_row)\n",
    "                    except Exception as e:\n",
    "                        #Swallow exceptions for now if things go wrong, the RSS feeds aren't 100% the same format\n",
    "                        print(f\"Error on reading RSS feed {rss_feed_url}\")\n",
    "                        print(e)\n",
    "\n",
    "                    i += 1\n",
    "\n",
    "                if not i == 0: #If feed has been updated, set last updated time to the newest item in the feed\n",
    "                    updated = True\n",
    "                    last_updated_list[rss_feed_url_index] = rss_datetime_converter(feed.entries[0])\n",
    "\n",
    "                rss_feed_url_index += 1\n",
    "            #Sleep after going through the entire list if no feeds were updated\n",
    "            if not updated:\n",
    "                time.sleep(sleep_time)\n",
    "\n",
    "    if column_names is None:\n",
    "        column_names = [\n",
    "            \"RssEntryTitle\",\n",
    "            \"PublishDatetime\",\n",
    "            \"RssFeedUrl\"\n",
    "        ]\n",
    "\n",
    "    if rss_attributes_method is None:\n",
    "        rss_attributes_method = _default_rss_attributes_method\n",
    "    if rss_datetime_converter is None:\n",
    "        rss_datetime_converter = _default_rss_datetime_converter\n",
    "\n",
    "    if thread_count is None:\n",
    "        table_writer = pd.DataFrame(columns=column_names)\n",
    "        thread = threading.Thread(target=thread_function, args=[rss_feed_urls, rss_attributes_method, rss_datetime_converter, sleep_time, table_writer])\n",
    "        thread.start()\n",
    "        return table_writer\n",
    "    else:\n",
    "        tables = []\n",
    "        thread_index = 0\n",
    "        urls_per_thread = math.ceil(len(rss_feed_urls)/thread_count)\n",
    "        while thread_index < thread_count:\n",
    "            table_writer = pd.DataFrame(columns=column_names)\n",
    "            start_index = thread_index * urls_per_thread\n",
    "            #Python doesn't check index bounds on list splices [:], so this works without needing any index checks\n",
    "            thread = threading.Thread(target=thread_function, args=[rss_feed_urls[start_index:start_index + urls_per_thread], rss_attributes_method, rss_datetime_converter, sleep_time, table_writer])\n",
    "            thread.start()\n",
    "            thread_index += 1\n",
    "            tables.append(table_writer)\n",
    "        return merge(tables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dcfae556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_default_sia_classifier_func(classifier):\n",
    "    def a(strn):\n",
    "        sentiment = classifier.polarity_scores(strn)\n",
    "        return [sentiment[\"pos\"], sentiment[\"neu\"], sentiment[\"neg\"], sentiment[\"compound\"]]\n",
    "    return a\n",
    "\n",
    "classifier = build_default_sia_classifier_func(SentimentIntensityAnalyzer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "82c93331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rss_attributes_seeking_alpha(entry):\n",
    "    return (entry[\"title\"], datetime_converter_seeking_alpha(entry), entry[\"title_detail\"][\"base\"])\n",
    "\n",
    "def datetime_converter_seeking_alpha(entry):\n",
    "    dt = parser.parse(entry[\"published\"])\n",
    "    dts = dt.strftime(\"%Y-%m-%dT%H:%M:%S\") + \" NY\"\n",
    "    return datetime(dts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "70a19128",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-11 (thread_function):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tomerkatzav/.pyenv/versions/3.10.3/lib/python3.10/threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/tomerkatzav/.pyenv/versions/3.10.3/lib/python3.10/threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/sb/h_f2fj514978bn50hwydfpvh0000gn/T/ipykernel_85017/984380087.py\", line 65, in thread_function\n",
      "  File \"/var/folders/sb/h_f2fj514978bn50hwydfpvh0000gn/T/ipykernel_85017/3087524447.py\", line 7, in datetime_converter_seeking_alpha\n",
      "TypeError: 'str' object cannot be interpreted as an integer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on reading RSS feed https://seekingalpha.com/feed.xml\n",
      "'str' object cannot be interpreted as an integer\n",
      "Error on reading RSS feed https://seekingalpha.com/feed.xml\n",
      "'str' object cannot be interpreted as an integer\n",
      "Error on reading RSS feed https://seekingalpha.com/feed.xml\n",
      "'str' object cannot be interpreted as an integer\n",
      "Error on reading RSS feed https://seekingalpha.com/feed.xml\n",
      "'str' object cannot be interpreted as an integer\n",
      "Error on reading RSS feed https://seekingalpha.com/feed.xml\n",
      "'str' object cannot be interpreted as an integer\n",
      "Error on reading RSS feed https://seekingalpha.com/feed.xml\n",
      "'str' object cannot be interpreted as an integer\n",
      "Error on reading RSS feed https://seekingalpha.com/feed.xml\n",
      "'str' object cannot be interpreted as an integer\n",
      "Error on reading RSS feed https://seekingalpha.com/feed.xml\n",
      "'str' object cannot be interpreted as an integer\n",
      "Error on reading RSS feed https://seekingalpha.com/feed.xml\n",
      "'str' object cannot be interpreted as an integer\n",
      "Error on reading RSS feed https://seekingalpha.com/feed.xml\n",
      "'str' object cannot be interpreted as an integer\n",
      "Error on reading RSS feed https://seekingalpha.com/feed.xml\n",
      "'str' object cannot be interpreted as an integer\n",
      "Error on reading RSS feed https://seekingalpha.com/feed.xml\n",
      "'str' object cannot be interpreted as an integer\n",
      "Error on reading RSS feed https://seekingalpha.com/feed.xml\n",
      "'str' object cannot be interpreted as an integer\n",
      "Error on reading RSS feed https://seekingalpha.com/feed.xml\n",
      "'str' object cannot be interpreted as an integer\n",
      "Error on reading RSS feed https://seekingalpha.com/feed.xml\n",
      "'str' object cannot be interpreted as an integer\n",
      "Error on reading RSS feed https://seekingalpha.com/feed.xml\n",
      "'str' object cannot be interpreted as an integer\n",
      "Error on reading RSS feed https://seekingalpha.com/feed.xml\n",
      "'str' object cannot be interpreted as an integer\n",
      "Error on reading RSS feed https://seekingalpha.com/feed.xml\n",
      "'str' object cannot be interpreted as an integer\n",
      "Error on reading RSS feed https://seekingalpha.com/feed.xml\n",
      "'str' object cannot be interpreted as an integer\n",
      "Error on reading RSS feed https://seekingalpha.com/feed.xml\n",
      "'str' object cannot be interpreted as an integer\n",
      "Error on reading RSS feed https://seekingalpha.com/feed.xml\n",
      "'str' object cannot be interpreted as an integer\n",
      "Error on reading RSS feed https://seekingalpha.com/feed.xml\n",
      "'str' object cannot be interpreted as an integer\n",
      "Error on reading RSS feed https://seekingalpha.com/feed.xml\n",
      "'str' object cannot be interpreted as an integer\n",
      "Error on reading RSS feed https://seekingalpha.com/feed.xml\n",
      "'str' object cannot be interpreted as an integer\n",
      "Error on reading RSS feed https://seekingalpha.com/feed.xml\n",
      "'str' object cannot be interpreted as an integer\n",
      "Error on reading RSS feed https://seekingalpha.com/feed.xml\n",
      "'str' object cannot be interpreted as an integer\n",
      "Error on reading RSS feed https://seekingalpha.com/feed.xml\n",
      "'str' object cannot be interpreted as an integer\n",
      "Error on reading RSS feed https://seekingalpha.com/feed.xml\n",
      "'str' object cannot be interpreted as an integer\n",
      "Error on reading RSS feed https://seekingalpha.com/feed.xml\n",
      "'str' object cannot be interpreted as an integer\n",
      "Error on reading RSS feed https://seekingalpha.com/feed.xml\n",
      "'str' object cannot be interpreted as an integer\n"
     ]
    }
   ],
   "source": [
    "rss_feed_urls = [\"https://seekingalpha.com/feed.xml\"]\n",
    "built_in_sia_seeking_alpha = read_rss_continual(rss_feed_urls, rss_attributes_method=rss_attributes_seeking_alpha, rss_datetime_converter=datetime_converter_seeking_alpha, sleep_time=120)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb239af4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'built_in_sia_seeking_alpha' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m built_in_sia_seeking_alpha \u001b[38;5;241m=\u001b[39m built_in_sia_seeking_alpha\u001b[38;5;241m.\u001b[39mupdate([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSentiment = (org.jpy.PyListWrapper)classifier(RssEntryTitle)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPositive = (double)Sentiment[0]\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeutral = (double)Sentiment[1]\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNegative = (double)Sentiment[2]\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompound = (double)Sentiment[3]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m ])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'built_in_sia_seeking_alpha' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "built_in_sia_seeking_alpha = built_in_sia_seeking_alpha.update([\"Sentiment = (org.jpy.PyListWrapper)classifier(RssEntryTitle)\",\n",
    "    \"Positive = (double)Sentiment[0]\",\n",
    "    \"Neutral = (double)Sentiment[1]\",\n",
    "    \"Negative = (double)Sentiment[2]\",\n",
    "    \"Compound = (double)Sentiment[3]\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848724a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10.3",
   "language": "python",
   "name": "jupyter_notebook_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
